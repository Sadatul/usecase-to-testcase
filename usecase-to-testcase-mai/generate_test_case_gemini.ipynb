{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Test case \n",
    "Step - 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import base64\n",
    "import getpass\n",
    "import json\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jsonl import *\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(usecase):\n",
    "    return \"\"\"You are a tester tasked with creating comprehensive test cases for a given usecase description.\n",
    "\n",
    "## Usecase description\n",
    "\n",
    "{\n",
    "    \"name\": \"Changing Personal Information\",\n",
    "    \"scenario\": \"A user wants to change or update his personal information\",\n",
    "    \"actors\": \"User\",\n",
    "    \"preconditions\": \"User must login to his account\",\n",
    "    \"steps\": [\n",
    "        \"User logs in to his account\",\n",
    "        \"User navigates to his profile settings\",\n",
    "        \"User clicks on the button to edit personal information\",\n",
    "        \"User updates the personal information (i.e Name, Gender, Birthday, Class Shift, Institution, Guadian's Name, Guadian's Mobile Number)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "## Testcase \n",
    "\n",
    "[\n",
    "    {\n",
    "        \"name\": \"Successful Personal Information Update\",\n",
    "        \"description\": \"Verify that a user can successfully update his personal information\",\n",
    "        \"input\": {\n",
    "            \"userId\": \"user_12345\",\n",
    "            \"name\": \"John Doe\",\n",
    "            \"gender\": \"Male\",\n",
    "            \"birthday\": \"1990-01-01\",\n",
    "            \"classShift\": \"Morning\",\n",
    "            \"institution\": \"ABC School\",\n",
    "            \"guardianName\": \"Jane Doe\",\n",
    "            \"guardianMobile\": \"01712345678\"\n",
    "        },\n",
    "        \"expected\": {\n",
    "            \"outcome\": \"Personal information update successful\",\n",
    "            \"status\": \"Information Updated\"\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Failed Personal Information Update\",\n",
    "        \"description\": \"Verify that a user cannot update his personal information if any of the provided information is empty\",\n",
    "        \"input\": {\n",
    "            \"userId\": \"user_12345\",\n",
    "            \"name\": \"John Doe\",\n",
    "            \"gender\": null,\n",
    "            \"birthday\": \"1990-01-01\",\n",
    "            \"classShift\": \"Morning\",\n",
    "            \"institution\": \"ABC School\",\n",
    "            \"guardianName\": \"Jane Doe\",\n",
    "            \"guardianMobile\": \"01712345678\"\n",
    "        },\n",
    "        \"expected\": {\n",
    "            \"outcome\": \"Personal information update failed\",\n",
    "            \"status\": \"Incorrect Information\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "## Usecase description\n",
    "\"\"\" + usecase + \"\"\"\n",
    "\n",
    "## Testcase\n",
    "\n",
    "\n",
    "--------\n",
    "**Important Instruction:**\n",
    "    - Understand the last usecase.\n",
    "    - Generate test cases similar to the given example that covers both:\n",
    "        - **Normal** and **Edge** case scenarios\n",
    "        - **Positive** and **Negative** case scenarios\n",
    "        - **Valid** and **Invalid** case scenarios\n",
    "    - Do not add any explanation or any unnecessary word.\n",
    "    - Your generated testcase must be json parsable and must follow the style of the given example.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API_KEY = getpass.getpass()\n",
    "API_KEY = \"AIzaSyBCku-r9OZW6DArQ519kPitTWDy2gsosVc\" # my\n",
    "# API_KEY = \"AIzaSyCYZFFO_Yr8C62LU2_HxGbOFZSYNEZKHi4\" # navid\n",
    "API_KEY = 'AIzaSyAO7RtjeI0u3w_-LhVNontaBBIxSm_NzHM' # my 2nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "# Create the model\n",
    "generation_config = {\n",
    "  \"temperature\": 0,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 40,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "  model_name=\"gemini-1.5-pro-002\",\n",
    "  generation_config=generation_config,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_response(response: str) -> str:\n",
    "    if response is None:\n",
    "        return ''\n",
    "    \n",
    "    if \"```\" not in response:\n",
    "        return response\n",
    "\n",
    "    code_pattern = r'```((.|\\n)*?)```'\n",
    "    if \"```json\" in response:\n",
    "        code_pattern = r'```json((.|\\n)*?)```'\n",
    "\n",
    "    code_blocks = re.findall(code_pattern, response, re.DOTALL)\n",
    "\n",
    "    if type(code_blocks[-1]) == tuple or type(code_blocks[-1]) == list:\n",
    "        code_str = \"\\n\".join(code_blocks[-1])\n",
    "    elif type(code_blocks[-1]) == str:\n",
    "        code_str = code_blocks[-1]\n",
    "    else:\n",
    "        code_str = response\n",
    "\n",
    "    return code_str.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_testcases(usecase):\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            response = model.generate_content(get_prompt(usecase))\n",
    "            # print(response.text)\n",
    "\n",
    "            return json.loads(parse_response(response.text))\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "            # if response is not None: print(response.text)\n",
    "            import time\n",
    "            time.sleep(60 * (i+1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_bert_score(reference, candidate):\n",
    "    P, R, F1 = score([candidate], [reference], lang=\"en\", verbose=False)\n",
    "    return P.mean().item(), R.mean().item(), F1.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"dataset/dataset-20.jsonl\"\n",
    "RESULTS_PATH = \"results/Gemini-results-20.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(RESULTS_PATH):\n",
    "    with open(RESULTS_PATH, mode=\"w\", encoding='utf-8') as file:\n",
    "        file.write(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = read_jsonl(RESULTS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read_jsonl(DATASET_PATH)[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, data in enumerate(dataset):\n",
    "    if len(results) > idx:\n",
    "        continue\n",
    "    \n",
    "    usecase = data[\"usecase\"]\n",
    "\n",
    "    if \"author\" in usecase: del usecase[\"author\"]\n",
    "    if \"id\" in usecase: del usecase[\"id\"]\n",
    "\n",
    "    usecase = json.dumps(usecase, indent=4)\n",
    "    \n",
    "    testcases = generate_testcases(usecase)\n",
    "\n",
    "    # p, r, f1 = calculate_bert_score(\n",
    "    #     reference=json.dumps(data[\"testcases\"], indent=4),\n",
    "    #     candidate=json.dumps(testcases, indent=4),\n",
    "    # )\n",
    "\n",
    "    results.append({\n",
    "        \"usecase\": data[\"usecase\"],\n",
    "        \"testcases\": data[\"testcases\"],\n",
    "        \"GPT4o_testcases\": testcases,\n",
    "        # \"bert_score\": {\n",
    "        #     \"Precision\": p,\n",
    "        #     \"Recall\": r,\n",
    "        #     \"F1\": f1\n",
    "        # }\n",
    "    })\n",
    "\n",
    "    write_jsonl(RESULTS_PATH, results)\n",
    "    # break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# precisions, recalls, f1_scores = [], [], []\n",
    "# for res in results:\n",
    "#     precisions.append(res[\"bert_score\"][\"Precision\"])\n",
    "#     recalls.append(res[\"bert_score\"][\"Recall\"])\n",
    "#     f1_scores.append(res[\"bert_score\"][\"F1\"])\n",
    "\n",
    "# print(f\"Average Precision: {(sum(precisions)*100)/len(precisions):0.2f}\")\n",
    "# print(f\"Average Recall: {(sum(recalls)*100)/len(recalls):0.2f}\")\n",
    "# print(f\"Average F1: {(sum(f1_scores)*100)/len(f1_scores):0.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "u2t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
